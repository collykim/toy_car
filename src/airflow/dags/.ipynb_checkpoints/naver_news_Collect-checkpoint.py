{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbd5c7-1750-45ba-a910-4bd00f714933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from fake_useragent import UserAgent\n",
    "import random\n",
    "import elementpath\n",
    "from lxml import etree\n",
    "from hdfs import InsecureClient\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': dt(2024, 1, 24),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'CollectNaverNews',\n",
    "    default_args=default_args,\n",
    "    description='IT Naver News Collect in Daily',\n",
    "    schedule_interval=\"@daily\"\n",
    ")\n",
    "\n",
    "def news_url_collect():\n",
    "    ua = UserAgent()  # UserAgent 객체 생성\n",
    "    user_agent = ua.random  # User-Agent 설정\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"disable-gpu\")\n",
    "    options.add_argument(\"lang=ko_KR\")\n",
    "    options.add_argument('Content-Type=application/json; charset=utf-8')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "    news_url_list = []\n",
    "    day = (dt.today()-timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    url = f'https://news.naver.com/breakingnews/section/103/239?date={day}'\n",
    "    driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(),options=options)\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            more_btn = driver.find_element(By.XPATH, '//div[@class=\"section_more\"]/a')\n",
    "            driver.execute_script(\"arguments[0].click();\",more_btn)\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//div[@class=\"section_more\"]/a')))  \n",
    "        except TimeoutException:\n",
    "            break\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tree = etree.HTML(str(soup))\n",
    "    hrefs = tree.xpath('//div[@class=\"section_latest\"]/div/div/div/ul/li/descendant::div[@class=\"sa_text\"]/a/@href')\n",
    "    news_url_list.extend(hrefs) \n",
    "\n",
    "    df = pd.DataFrame(news_url_list, columns =['news_url_list'])\n",
    "\n",
    "    df.to_csv(f\"/home/ubuntu/naver_news_list/{day}_car_News_URL.csv\", index = None)\n",
    "\n",
    "news_Url_Collect_task = PythonOperator(\n",
    "    task_id='news_url_collect',\n",
    "    python_callable=news_url_collect,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "def news_Content_Comment_Collect():\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    ua = UserAgent()  # UserAgent 객체 생성\n",
    "    user_agent = ua.random  # User-Agent 설정\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"disable-gpu\")\n",
    "    options.add_argument(\"lang=ko_KR\")\n",
    "    options.add_argument('Content-Type=application/json; charset=utf-8')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "\n",
    "    news_idx = 0\n",
    "    news_comment_idx = 0\n",
    "    day = (dt.today()-timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    news_df = pd.DataFrame(columns = (\"title\",\"url\",\"datetime\",\"content\"))\n",
    "    news_comment_df = pd.DataFrame(columns = (\"title\",\"url\",\"datetime\",\"content\",\"c_author\",\"c_datetime\",\"c_content\"))\n",
    "    news_url_list = pd.read_csv(f\"/home/ubuntu/naver_news_list/{day}_car_News_URL.csv\")\n",
    "    news_url_list = list(news_url_list['news_url_list'])\n",
    "\n",
    "    for url in news_url_list:\n",
    "        driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(),options=options)\n",
    "        logging.info(\"접속완료\")\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)\n",
    "        logging.info(f'{news_idx} Start')\n",
    "        #본문수집\n",
    "        try:\n",
    "            title = driver.find_element(By.XPATH, '//div[@class=\"media_end_head_title\"]/h2/span').text\n",
    "            url = url\n",
    "            datetime = driver.find_element(By.XPATH, '//div[@class=\"media_end_head_info_datestamp_bunch\"]/span').text\n",
    "            content = driver.find_element(By.XPATH, '//div[@class=\"newsct_article _article_body\"]').text.replace('\\n','')\n",
    "            news_df.loc[news_idx] = [title,url,datetime, content]\n",
    "            news_idx += 1\n",
    "            comment_page = driver.find_element(By.XPATH, '//div[@class=\"media_end_head_info_variety_cmtcount _COMMENT_HIDE\"]/a')\n",
    "            driver.execute_script(\"arguments[0].click();\",comment_page)\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    more_btn = driver.find_element(By.XPATH, '//span[@class=\"u_cbox_page_more\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\",more_btn)\n",
    "                    WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//span[@class=\"u_cbox_page_more\"]')))  \n",
    "                except TimeoutException:\n",
    "                    break\n",
    "\n",
    "            comments = driver.find_elements(By.XPATH, '//div[@class=\"u_cbox_comment_box u_cbox_type_profile\"]')\n",
    "\n",
    "            for comment in comments:\n",
    "                try:\n",
    "                    c_author = comment.find_element(By.XPATH,'.//span[@class=\"u_cbox_nick\"]').text\n",
    "                    c_datetime = comment.find_element(By.XPATH,'.//span[@class=\"u_cbox_date\"]').text\n",
    "                    c_content = comment.find_element(By.XPATH,'.//span[@class=\"u_cbox_contents\"]').text\n",
    "\n",
    "                    news_comment_df.loc[news_comment_idx] = [title,url,datetime, content, c_author, c_datetime, c_content]\n",
    "                    news_comment_idx += 1\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        driver.quit()\n",
    "        logging.info(f'{news_idx} End')\n",
    "        time.sleep(random.randint(2,3))\n",
    "\n",
    "    df = pd.merge(news_df,news_comment_df)\n",
    "\n",
    "    parquet_buffer = BytesIO()\n",
    "    df.to_parquet(parquet_buffer, index=False)\n",
    "\n",
    "    # S3에 연결\n",
    "    s3 = boto3.client('s3', aws_access_key_id='AKIA4LH2MAOFAW5PUKUT',\n",
    "                    aws_secret_access_key='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')\n",
    "\n",
    "    # 버킷 이름과 저장할 파일 경로 설정\n",
    "    bucket_name = 'hyunwoo-toy-project-bucket'\n",
    "    file_path = f'naver_news/{day}_news.parquet'\n",
    "\n",
    "    # 버킷에 Parquet 파일 저장\n",
    "    parquet_buffer.seek(0)\n",
    "    s3.upload_fileobj(parquet_buffer, bucket_name, file_path)\n",
    "\n",
    "news_Content_Comment_Collect_task = PythonOperator(\n",
    "    task_id='news_Content_Comment_Collect',\n",
    "    python_callable=news_Content_Comment_Collect,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#Task 실행순서\n",
    "news_Url_Collect_task >> news_Content_Comment_Collect_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
